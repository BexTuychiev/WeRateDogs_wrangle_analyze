{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In wrangle_act notebook, I have preformed several actions to clean three datasets.\n",
    "\n",
    "I created the first dataset, we_rd, from the WeRateDogs enhanced twitter archive. The dataset inlcluded almost 2500 records of tweets and their id, rating, dog stage, etc. columns. Then, using requests library, I downloaded the contents of tweets corresponding to the tweet_id column in the first dataset. I stored the like count and the number of retweets from a json file to a second dataset, tweets_selected. Final dataset included the results of neural network algorithm to identify the dog breeds. The data was given a direct access for those who could not get the Twitter API devlepor account.\n",
    "\n",
    "Overall, I have identified 9 quality and 7 tidiness issues and I have successfully eliminated them. In the final staged, I saved the predictions dataframe to a new csv file, whereas for the twitter archive and selected tweets, I joind them into a single master dataframe and saved them to a csv file, ready for analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('da_nanodegree': conda)",
   "language": "python",
   "name": "python37664bitdananodegreeconda551fcb2ecfa842b7a09bf3cc4a8f59b7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
